{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, re\n",
    "from math import isclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_RE = re.compile(\"slurm-([0-9]+)(.out|)$\")\n",
    "\n",
    "bs_RE = re.compile(\".*Train Buffer Size: 0, training batch size: ([0-9]+)\")\n",
    "ranks_RE = re.compile(\"ranks [0-9]+ ([0-9]+)\")\n",
    "lrscale_RE = re.compile(\"lrScaling ([a-zA-Z0-9]+)\")\n",
    "lr_RE = re.compile(\".*Skaling learning rate from ([0-9.e+-]+) to ([0-9.e+-]+) due to bs factor ([0-9.e+-]+)\")\n",
    "param_RE = re.compile(\".*#Param ([a-zA-Z0-9._]+)= ([a-zA-Z0-9._/-]+)\")\n",
    "\n",
    "#runF_RE = re.compile(\"([0-9]+)-nodes_lr-([0-9.]+)_min-tb-([0-9]+)(?:_lrAE-([0-9]+))?$\")\n",
    "runF_RE = re.compile(\"([0-9]+)-nodes_lr-([0-9.e-]+)_min-tb-([0-9]+)_lrAE-([0-9]+)_bs-([0-9]+)$\")\n",
    "\n",
    "lossDat_RE = re.compile(\"loss_([0-9]+).dat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRuns(path=\"../\"):\n",
    "    runs = {}\n",
    "    \n",
    "    for fn in os.listdir(path):\n",
    "        m = run_RE.match(fn)\n",
    "        if not m:\n",
    "            continue\n",
    "\n",
    "        i = m[1]\n",
    "        if i in runs:\n",
    "            run = runs[i]\n",
    "        else:\n",
    "            run = {\"i\": i, \"path\":path, \"nnodes\":1}\n",
    "        \n",
    "        found = 0\n",
    "        if m[2] == \".out\":\n",
    "            with open(os.path.join(path, fn)) as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            ranks = 0\n",
    "            for l in lines:\n",
    "                    \n",
    "                m = ranks_RE.match(l)\n",
    "                if m:\n",
    "                    ranks += 1\n",
    "                    continue\n",
    "            \n",
    "                m = lrscale_RE.match(l)\n",
    "                if m and not \"lrscaling\" in run:\n",
    "                    run[\"lrscaling\"] = m[1]\n",
    "                    found += 1\n",
    "                    \n",
    "                m = lr_RE.match(l)\n",
    "                if m and not \"lr\" in run:\n",
    "                    run[\"lr\"] = m[1]\n",
    "                    run[\"lrscaled\"] = m[2]\n",
    "                    run[\"lrfactor\"] = m[3]\n",
    "                    found += 1\n",
    "                    \n",
    "                m = param_RE.match(l)\n",
    "                if m:\n",
    "                    run[m[1]] = m[2]\n",
    "                    \n",
    "            if found < 2:\n",
    "                if not \"lrscaling\" in run:\n",
    "                    run[\"lrscaling\"] = \"_\"\n",
    "                    found += 1\n",
    "                if not \"lr\" in run:\n",
    "                    run[\"lr\"] = float(\"nan\")\n",
    "                    run[\"lrscaled\"] = 1\n",
    "                    run[\"lrfactor\"] = 1\n",
    "                    found += 1\n",
    "            if found < 2:\n",
    "                    print(\"[WW] Meta data missign from {} file\".format(fn))\n",
    "                    print(run)\n",
    "                    continue\n",
    "            \n",
    "            if ranks == 0:\n",
    "                print(\"[WW] No ranks in run {}\".format(fn))\n",
    "\n",
    "            run[\"ranks\"] = ranks\n",
    "            \n",
    "            runs[i] = run\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLosses(col, runs, title=None, smoothWindow=20, filt=None):\n",
    "    li = list(runs.keys())\n",
    "    li.sort()\n",
    "    for i in li:\n",
    "        r = runs[i]\n",
    "        \n",
    "        if filt is not None:\n",
    "            for f in filt:\n",
    "                if f[0] not in r:\n",
    "                    print(\"Ignoring filter for non-present property:\", f[0])\n",
    "                    continue\n",
    "                if r[f[0]] not in f[1]:\n",
    "                    r = None\n",
    "                    break\n",
    "            if r is None:\n",
    "                continue\n",
    "        \n",
    "        i = r[\"i\"]\n",
    "        if not \"dat\" in r:\n",
    "            r[\"dat\"] = np.loadtxt(\"{}/slurm-{}/loss_0.dat\".format(r[\"path\"], i))\n",
    "        dat = r[\"dat\"]\n",
    "        #print(i, dat.shape)\n",
    "        if \"lrscale\" in r:\n",
    "            lrscale = r[\"lrscale\"]\n",
    "        else:\n",
    "            lrscale = \"1\"\n",
    "        linestyle = \"-\"\n",
    "        if lrscale == \"sqrt\":\n",
    "            linestyle = \":\"\n",
    "        if \"lr\" in r:\n",
    "            lr = r[\"lr\"]\n",
    "            lrscaled = r[\"lrscaled\"]\n",
    "        else:\n",
    "            lr = \"nan\"\n",
    "            lrscaled = \"nan\"\n",
    "            \n",
    "        if \"type_streamer\" in r:\n",
    "            if r[\"type_streamer\"] == \"streaming\":\n",
    "                linestyle = \"-\"\n",
    "                \n",
    "        smooth = np.convolve(dat[:, col], np.ones(smoothWindow)/smoothWindow, mode='valid')\n",
    "        d = (dat.shape[0] - smooth.shape[0] ) // 2\n",
    "        lrAEmult = r.get(\"config.lrAEmult\", 1)\n",
    "        \n",
    "        rep = r.get(\"trainBatchBuffer_config.min_tb_from_unchanged_now_bf\", 0)\n",
    "        if rep == \"8\":\n",
    "            linestyle = \":\"\n",
    "        #print(rep, linestyle)\n",
    "        \n",
    "        if int(lrAEmult) == 1:\n",
    "            linestyle = \":\"\n",
    "\n",
    "        plt.plot(dat[d:-d-1, 0], smooth,\n",
    "                 label=(\"{}: r{} bs{} lr{}->{} lrAEmult{}\".format(i, r[\"ranks\"], \"_\", lr, lrscaled, lrAEmult)),\n",
    "                 ls=linestyle)\n",
    "    if title is None:\n",
    "        plt.title(f\"col {col}\")\n",
    "    else:\n",
    "        plt.title(title)\n",
    "    #plt.ylim((0,10))\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    #plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path=\"/bigdata/hplsim/scratch/kelling//oldBSruns/\"\n",
    "path=\"/bigdata/hplsim/scratch/kelling//fixedBSruns/\"\n",
    "path=\"/bigdata/hplsim/scratch/kelling//scaledlrRuns/\"\n",
    "\n",
    "path=\"/bigdata/hplsim/scratch/kelling/chamfers/lrAE\"\n",
    "path=\"/bigdata/hplsim/aipp/SC24_PIConGPU-Continual-Learning/frontierNew\"\n",
    "\n",
    "runs = loadRuns(path)\n",
    "#runs2 = loadRuns(\"../runs_CL\")\n",
    "#runs.update(runs2)\n",
    "\n",
    "#runs = loadRuns(path)\n",
    "#runs2 = loadRuns(\"/bigdata/hplsim/scratch/kelling/chamfers/\")\n",
    "#runs.update(runs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(\"config.lrAEmult\", (5,20,40,80,100,150,200,600,800,1000))\n",
    "filt = [(\"trainBatchBuffer_config.min_tb_from_unchanged_now_bf\", (\"4\",)), (\"config.lrAEmult\", (\"15\",\"20\",\"25\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLosses(5, runs, smoothWindow=20, filt=None)\n",
    "plt.ylim((0,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotLosses(7, runs, smoothWindow=200, filt=filt)\n",
    "plt.ylim((1,5))\n",
    "#plt.xlim((0,6000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLosses(8, runs, smoothWindow=100, filt=filt)\n",
    "#plt.ylim((440,460))\n",
    "plt.ylim((256,258))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLosses(9, runs, smoothWindow=100, filt=filt)\n",
    "#plt.ylim((302.7,390))\n",
    "#plt.ylim((345,346))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in runs.values():\n",
    "    dat = r[\"dat\"]\n",
    "    print(r[\"i\"], r[\"ranks\"], r[\"bs\"], np.mean(dat[10:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRun(i, path):\n",
    "    \n",
    "    gpath = os.path.join(path, \"training.out\")\n",
    "    if not os.path.isfile(gpath):\n",
    "        gpath = os.path.join(path, \"out.txt\")\n",
    "        if not os.path.isfile(gpath):\n",
    "            raise RuntimeError(\"the path '{}' does not appear to be a training run.\".format(path))\n",
    "            \n",
    "    with open(gpath) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    run = {\"i\": i, \"path\": path}\n",
    "\n",
    "    ranks = 0\n",
    "    for l in lines:\n",
    "        m = bs_RE.match(l)\n",
    "        if m and not \"bs\" in run:\n",
    "            run[\"bs\"] = int(m[1])\n",
    "\n",
    "        lr_RE = re.compile(\".*Skaling learning rate from ([0-9.e+-]+) to ([0-9.e+-]+) due to bs factor ([0-9.e+-]+)\")\n",
    "        m = lr_RE.match(l)\n",
    "\n",
    "        if m:\n",
    "            if \"lr\" in run and not isclose(float(m[1]), run[\"lr\"]):\n",
    "                print(\"[WW] loss info in file path and training.out mismatch.\")\n",
    "            run[\"lr\"] = float(m[1])\n",
    "            run[\"lrscaled\"] = float(m[2])\n",
    "            run[\"lrfactor\"] = float(m[3])\n",
    "\n",
    "        m = param_RE.match(l)\n",
    "        if m:\n",
    "            run[m[1]] = m[2]\n",
    "            \n",
    "        m = ranks_RE.match(l)\n",
    "        if m:\n",
    "            ranks += 1\n",
    "\n",
    "    run[\"ranks\"] = ranks\n",
    "\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRunsF(path=\"/bigdata/hplsim/aipp/SC24_PIConGPU-Continual-Learning/03-30_learning-rate-scaling-with-ranks_chamfersdistance_fix-gpu-volume\"):\n",
    "    runs = {}\n",
    "    \n",
    "    for fn in os.listdir(path):\n",
    "        mf = runF_RE.match(fn)\n",
    "        #print(fn, mf)\n",
    "        if mf is None:\n",
    "            continue\n",
    "        \n",
    "        subruns = []\n",
    "        gpath = os.path.join(path, fn)\n",
    "        if os.path.isfile(os.path.join(gpath, \"training.out\")):\n",
    "            subruns.append((gpath,fn))\n",
    "        else:\n",
    "            for fnr in os.listdir(gpath):\n",
    "                ipath = os.path.join(gpath, fnr)\n",
    "                if os.path.isdir(ipath) and os.path.isfile(os.path.join(ipath, \"training.out\")):\n",
    "                    subruns.append((ipath, os.path.join(fn,fnr)))\n",
    "   \n",
    "        for gpath, i in subruns:\n",
    "\n",
    "            run = {\"rep\":int(mf[3]), \"lr\":float(mf[2]), \"nnodes\":int(mf[1])}\n",
    "                \n",
    "            run.update(loadRun(i, gpath))\n",
    "            \n",
    "            runs[i] = run\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDat(path):\n",
    "    dats = []\n",
    "    n = 0\n",
    "    datdir = os.path.join(path, \"simOutput\")\n",
    "    if not os.path.isdir(datdir):\n",
    "        datdir = path\n",
    "    for fn in os.listdir(datdir):\n",
    "        m = lossDat_RE.match(fn)\n",
    "        if not m:\n",
    "            continue\n",
    "        fpath = os.path.join(datdir, fn)\n",
    "        dat = np.loadtxt(fpath)\n",
    "        dats.append(dat)\n",
    "    \n",
    "    l = min(d.shape[0] for d in dats)\n",
    "    dats = np.stack(d[:l] for d in dats)\n",
    "    \n",
    "    return np.mean(dats, axis=0), np.std(dats, axis=0), dats\n",
    "\n",
    "def filtDict(d, filt):\n",
    "    ret = {}\n",
    "    for i, r in d.items():\n",
    "        for f in filt:\n",
    "            if f[0] not in r:\n",
    "                print(\"Ignoring filter for non-present property:\", f[0])\n",
    "                continue\n",
    "            if r[f[0]] not in f[1]:\n",
    "                r = None\n",
    "                break\n",
    "        if r is not None:\n",
    "            ret[i] = r\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def plotLossesF(col, runs, title=None, smoothWindow=20, filt=None):\n",
    "    li = list(runs.keys())\n",
    "    li.sort()\n",
    "    for i in li:\n",
    "        r = runs[i]\n",
    "\n",
    "        if filt is not None:\n",
    "            for f in filt:\n",
    "                if f[0] not in r:\n",
    "                    print(\"Ignoring filter for non-present property:\", f[0])\n",
    "                    continue\n",
    "                if r[f[0]] not in f[1]:\n",
    "                    r = None\n",
    "                    break\n",
    "            if r is None:\n",
    "                continue\n",
    "\n",
    "        i = r[\"i\"]\n",
    "        \n",
    "        if \"dat\" not in r:\n",
    "            r[\"dat\"], r[\"datStdev\"], r[\"dats\"] = loadDat(r[\"path\"])\n",
    "            \n",
    "            \n",
    "        dat = r[\"dat\"]\n",
    "        #print(i, dat.shape)\n",
    "        if \"lrscale\" in r:\n",
    "            lrscale = r[\"lrscale\"]\n",
    "        else:\n",
    "            lrscale = \"1\"\n",
    "        linestyle = \"-\"\n",
    "        if lrscale == \"sqrt\":\n",
    "            linestyle = \":\"\n",
    "        if \"lr\" in r:\n",
    "            lr = r[\"lr\"]\n",
    "            lrscaled = r.get(\"lrscaled\", lr)\n",
    "        else:\n",
    "            lr = \"nan\"\n",
    "            lrscaled = \"nan\"\n",
    "            \n",
    "        nnodes = r.get(\"nnodes\", 1)\n",
    "            \n",
    "        if nnodes == 48:\n",
    "            linestyle = \"-.\"\n",
    "        elif nnodes == 24:\n",
    "            linestyle = \"--\"\n",
    "        elif nnodes == 72:\n",
    "            linestyle = \"-\"\n",
    "        elif nnodes == 96:\n",
    "            linestyle = \":\"\n",
    "        smooth = np.convolve(dat[:, col], np.ones(smoothWindow)/smoothWindow, mode='valid')\n",
    "        d = (dat.shape[0] - smooth.shape[0] ) // 2\n",
    "        rep = r.get(\"trainBatchBuffer_config.min_tb_from_unchanged_now_bf\", 0)\n",
    "        if rep == 8:\n",
    "            linestyle = \";\"\n",
    "        plt.plot(dat[d:-d-1, 0], smooth,\n",
    "                 label=(\"{}: r{} bs{} lr{}->{} rep{}\".format(i, r[\"ranks\"], \"_\", lr, lrscaled, rep)),\n",
    "                 ls=linestyle)\n",
    "    if title is None:\n",
    "        plt.title(f\"col {col}\")\n",
    "    else:\n",
    "        plt.title(title)\n",
    "    #plt.ylim((0,10))\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    #plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runsh = runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/bigdata/hplsim/aipp/SC24_PIConGPU-Continual-Learning/03-31_independent-AE-scaling_chamfersdistance_fix-gpu-volume_scaling\"\n",
    "path = \"/bigdata/hplsim/aipp/SC24_PIConGPU-Continual-Learning/03-30_learning-rate-scaling-with-ranks_chamfersdistance_fix-gpu-volume\"\n",
    "#path = \"/bigdata/hplsim/aipp/SC24_PIConGPU-Continual-Learning/04-01_rerun-independent-AE-scaling_chamfersdistance_fix-gpu-volume_scaling/\"\n",
    "path= \"/bigdata/hplsim/aipp/SC24_PIConGPU-Continual-Learning/frontierNew\"\n",
    "runs = loadRunsF(path)\n",
    "#runs.update(runs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### filt = [(\"rep\", (16,)), (\"lr\", (.0001,))]\n",
    "#filt = [(\"nnodes\", (96,))]\n",
    "filt=None\n",
    "runsf = runs #filtDict(runs, filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\"hemera\": loadRun(\"hemera\", \"/bigdata/hplsim/aipp/SC24_PIConGPU-Continual-Learning/04-02_single-gpu-offline-training-from-24-node_hemera/trainingOutput\")}\n",
    "runs[\"frontier\"] = loadRun(\"frontier\", \"/bigdata/hplsim/aipp/SC24_PIConGPU-Continual-Learning/04-02_single-gpu-offline-training-from-24-node_hemera/trainingOutput\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(runsh.keys()))\n",
    "for i in ['6923925', '6926891']:\n",
    "    runs[i] = runsh[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = [(\"bs\", (4,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotLossesF(5, runs, smoothWindow=20, filt=filt)\n",
    "plt.ylim((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLossesF(7, runs, smoothWindow=10, filt=filt)\n",
    "plt.ylim((0,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLossesF(9, runs, smoothWindow=10, filt=filt)\n",
    "#plt.ylim((225,327))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLossesF(9, runs, smoothWindow=20, filt=filt)\n",
    "plt.ylim((302,304))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "runsf = runs #filtDict(runs, filt)\n",
    "col = 7\n",
    "for r in runsf.values():\n",
    "    plt.title(r[\"i\"])\n",
    "    dats = r[\"dats\"]\n",
    "    for d in range(dats.shape[0]):\n",
    "        if d not in [0,3,4,7,8]:\n",
    "        #if d not in [1,2,5,6,9]:\n",
    "            pass\n",
    "        plt.plot(dats[d, :, 0], dats[d, :, col], label=str(d))\n",
    "\n",
    "    plt.ylim(0,6)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runss = {}\n",
    "\n",
    "def dcp(k, a = runss, b = runsf):\n",
    "    a[k] = b[k]\n",
    "\n",
    "idstr = \"{}-nodes_lr-{}_min-tb-{}\"\n",
    "dcp(idstr.format(96, \"0.0005\", 16))\n",
    "dcp(idstr.format(96, \"0.0001\", 16))\n",
    "dcp(idstr.format(96, \"0.0005\", 8))\n",
    "\n",
    "dcp(idstr.format(24, \"0.0001\", 16))\n",
    "dcp(idstr.format(24, \"0.0001\", 8))\n",
    "dcp(idstr.format(24, \"0.0001\", 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plotLossesF(5, runss, smoothWindow=20, filt=None)\n",
    "plt.ylim((0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "runsf = filtDict(runs, [(\"bs\", (4,)), (\"rep\", (96,)) ])\n",
    "\n",
    "perf = {}\n",
    "for r in runsf.values():\n",
    "    if \"dat\" not in r:\n",
    "        r[\"dat\"], r[\"datStdev\"] = loadDat(r[\"path\"])\n",
    "    dat = r[\"dat\"][:, 1]\n",
    "    \n",
    "    #i = \"lr{} rep{}\".format(r[\"lr\"], r[\"rep\"])\n",
    "    i = int(r[\"rep\"])\n",
    "    if i not in perf:\n",
    "        perf[i] = {}\n",
    "    if r[\"nnodes\"] not in perf[i]:\n",
    "        perf[i][r[\"nnodes\"]] = []\n",
    "    perf[i][r[\"nnodes\"]].append(dat)\n",
    "    \n",
    "for i in perf:\n",
    "    r = perf[i]\n",
    "    for n in r:\n",
    "        dat = np.concatenate(r[n])\n",
    "        mean = np.mean(dat)\n",
    "        std = np.std(dat)\n",
    "        dat = dat[np.argwhere(np.abs(dat - mean)/std < 4.)]\n",
    "        mean = np.mean(dat)\n",
    "        std = np.std(dat)\n",
    "        r[n] = (mean, std)\n",
    "        \n",
    "    d = np.column_stack([np.array(list(r.keys())), np.array(list(r.values()))])\n",
    "    arg = np.argsort(d[:,0])\n",
    "    perf[i] = d[arg]\n",
    "\n",
    "srt = list(perf.keys())\n",
    "srt.sort()\n",
    "\n",
    "print(r)\n",
    "    \n",
    "for i in srt:\n",
    "    r = perf[i]\n",
    "    #print(r)\n",
    "    r[:, 1] = r[0, 1] / r[:, 1]\n",
    "    \n",
    "    rep = i\n",
    "    if rep == 4:\n",
    "        style = dict(marker='x', linestyle='-')\n",
    "    elif rep == 8:\n",
    "        style = dict(marker='+', linestyle='--')\n",
    "    elif rep == 16:\n",
    "        style = dict(marker='o', linestyle='-.')\n",
    "    \n",
    "    #plt.errorbar(perf[i][0][:,0], perf[i][0][:,1], yerr=perf[i][0][:,2], label=i, **style)\n",
    "    #plt.ylim(70,100)\n",
    "    plt.xlim(0,100)\n",
    "    plt.plot(r[:, 0], r[:,1]*100, label='$n_\\mathrm{{rep}} = {}$'.format(i), **style)\n",
    "    #t = r[\"dat\"]\n",
    "    \n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "plt.tick_params(direction=\"in\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"number of nodes\")\n",
    "plt.ylabel(\"efficiency [%]\")\n",
    "plt.xticks([8,24,48,96])\n",
    "#plt.legend(loc='lower left', fontsize=\"14\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"frontier_training_weak-scaling.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs['24-nodes_lr-0.001_min-tb-8'][\"dat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ar = np.array([8,24,48,72,96.]*3)\n",
    "ar = np.reshape(ar, (3, ar.shape[0]//3))\n",
    "print(ar)\n",
    "l = []\n",
    "for i in range(ar.shape[1]):\n",
    "    d = ar[0, i]\n",
    "    dat = np.loadtxt(\"/home/kelling/checkout/FWKT/InSituML/main/ModelHelpers/cINN/pic/{}_timesteps_averages.dat\".format(int(d)))\n",
    "    t = dat[:,2:]\n",
    "    print(t.shape)\n",
    "    mean = np.mean(t, axis=1)\n",
    "    std = np.std(t, axis=1)\n",
    "    #print(np.argwhere(np.abs(dat - mean)/std < 4.))\n",
    "    #print(dat.shape, mean.shape)\n",
    "    #dat = dat[np.argwhere(np.abs(dat.T - mean)/std < 4.)]\n",
    "    #print(dat)\n",
    "    #mean = np.mean(dat, axis=1)\n",
    "    #std = np.std(dat, axis=1)\n",
    "    print(mean.shape)\n",
    "    l.append(mean)\n",
    "    #ar[1, i] = mean\n",
    "    #ar[2, i] = std\n",
    "    break\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dat[:, 1], mean, marker=\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.load(\"picks.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(l.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
