{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355c1518-68dd-46be-b80e-c1c18f77a2e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nflows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13371/924743445.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_MAF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#from model.modules import dataset_supercell_timestep as dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/insitu_particles/InSituML/main/ModelHelpers/cINN/model/model_MAF.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./modules'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnflows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nflows'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from model import model_MAF\n",
    "from model.modules import data_preprocessing\n",
    "#from model.modules import dataset_supercell_timestep as dataset\n",
    "from model.modules import dataset_supercell_timestep_as_hotvec as dataset\n",
    "from model.modules import loader\n",
    "from model.modules import utils\n",
    "from model.modules import visualizations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker as tick\n",
    "from matplotlib import cm\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 10)\n",
    "plt.rcParams['xtick.labelsize']=20\n",
    "plt.rcParams['ytick.labelsize']=20\n",
    "plt.rcParams['lines.linewidth']=6\n",
    "params = {'mathtext.default': 'regular' }          \n",
    "plt.rcParams.update(params)\n",
    "\n",
    "#get_radiation_data = data_preprocessing.get_radiation_spectra_2_projections\n",
    "get_radiation_data = data_preprocessing.get_radiation_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "024e1646-c95c-4fd2-848f-6d554e3deecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(pc, pc_pred, axs, comp_x, label_x):\n",
    "    axs.hist(pc[:,comp_x], density=True, bins=30, label='Groundtruth', alpha = 0.4)  # density=False would make counts\n",
    "    axs.hist(pc_pred[:,comp_x], density=True, bins=30, label='Reconstruction', alpha = 0.4)  # density=False would make counts\n",
    "    axs.set_ylabel('Probability')\n",
    "    axs.set_xlabel(label_x)\n",
    "    axs.grid(True)\n",
    "    axs.legend(fontsize=18)\n",
    "\n",
    "def plot_2D_GTandRec(pc, pc_pred, comp_x, comp_y, axs, label_x, label_y):\n",
    "    axs.scatter(pc[:,comp_x], pc[:,comp_y], s=30, alpha=0.75, label='Groundtruth')\n",
    "    if pc_pred is not None:\n",
    "        axs.scatter(pc_pred[:,comp_x], pc_pred[:,comp_y], s=30, alpha=0.4, label='Prediction')\n",
    "    axs.tick_params(axis='y', which='major', rotation=45)\n",
    "    axs.grid(True)\n",
    "    axs.set_xlabel(label_x)\n",
    "    axs.set_ylabel(label_y)\n",
    "    axs.legend(fontsize=18)\n",
    "    \n",
    "def plot_2D(pc, comp_x, comp_y, axs, label_x, label_y):\n",
    "    axs.scatter(pc[:,comp_x], pc[:,comp_y], s=15, alpha=0.2)\n",
    "    axs.tick_params(axis='y', which='major', rotation=45)\n",
    "    axs.grid(True)\n",
    "    axs.set_xlabel(label_x)\n",
    "    axs.set_ylabel(label_y)\n",
    "    \n",
    "def reject_outliers(data, m=4):\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efedc09e-1ff6-4272-a29c-1181c3dda8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10700\n"
     ]
    }
   ],
   "source": [
    "timesteps = ['10000', '10100', '10200', '10300', '10400', '10500', '10600', '10700', '10800', '10900', '11000']\n",
    "timestep = timesteps[7]\n",
    "print(timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8564de2-b63f-4826-8d51-07a58e684b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/10700_43_1150_51.npy', '/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/10700_44_1151_51.npy', '/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/10700_43_1151_51.npy', '/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/10700_44_1150_50.npy', '/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/10700_43_1150_50.npy', '/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/10700_43_1151_50.npy', '/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/10700_44_1151_50.npy', '/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/10700_44_1150_51.npy']\n",
      "43_1150_51\n",
      "/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/10200_43_1150_51.npy\n",
      "/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/10300_43_1150_51.npy\n",
      "/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/10400_43_1150_51.npy\n",
      "/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/10600_43_1150_51.npy\n",
      "/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/10700_43_1150_51.npy\n",
      "/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/10800_43_1150_51.npy\n",
      "/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/10900_43_1150_51.npy\n"
     ]
    }
   ],
   "source": [
    "unique_supercells = []\n",
    "all_timesteps = []\n",
    "\n",
    "unique_supercells = ['/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/'+nextfile for nextfile in os.listdir('/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI') if timesteps[7] in nextfile]\n",
    "print(unique_supercells)\n",
    "supercell = '_'.join(unique_supercells[0].split('/')[-1].split('.')[0].split('_')[1:])\n",
    "all_timesteps = ['/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI/'+nextfile for nextfile in os.listdir('/bigdata/hplsim/aipp/Anna/lwfa_2cells_unitSI') if supercell in nextfile]\n",
    "print(supercell)\n",
    "all_timesteps.sort()\n",
    "for timestep in all_timesteps:\n",
    "    print(timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ae3c279-03e3-422d-8d4c-a9cb86014465",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7781f778688b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m datasets.append(dataset.PCDataset(items_phase_space=all_timesteps[:2],\n\u001b[0;32m----> 5\u001b[0;31m                                normalize=True, a=0., b=1.))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mloader_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mps_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/insitu_particles/InSituML/main/ModelHelpers/cINN/model/modules/dataset_supercell_timestep_as_hotvec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, items_phase_space, normalize, a, b)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_ps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmin_ps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmax_ps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "models = []\n",
    "\n",
    "datasets.append(dataset.PCDataset(items_phase_space=all_timesteps[:2],\n",
    "                               normalize=True, a=0., b=1.))\n",
    "loader_tr = loader.get_loader(datasets[0], batch_size=1)\n",
    "ps_dim = 0\n",
    "radiation_dim = 0\n",
    "for ps, rad in loader_tr:\n",
    "    print(ps.shape)\n",
    "    print(rad.shape)\n",
    "\n",
    "    ps_dim = ps.shape[-1]\n",
    "    radiation_dim = rad.shape[-1]\n",
    "    break\n",
    "\n",
    "print('radiation dim ', radiation_dim)\n",
    "\n",
    "models.append(model_MAF.PC_MAF(dim_condition=radiation_dim,\n",
    "                           dim_input=9,\n",
    "                           num_coupling_layers=5,\n",
    "                           hidden_size=256,\n",
    "                           device='cpu',\n",
    "                           enable_wandb=False,\n",
    "                           weight_particles=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2648ca6-c1c4-4a31-89c9-6d94dd805c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = []\n",
    "test_pointclouds = []\n",
    "\n",
    "optimizers.append(torch.optim.Adam(models[0].model.parameters(), lr=1e-4,\n",
    "                         betas=(0.8, 0.9), eps=1e-6, weight_decay=2e-5))\n",
    "test_pointclouds.append(all_timesteps[7])\n",
    "    \n",
    "test_radiation = \"/bigdata/hplsim/production/LWFA_radiation_new/LWFArad_data_example/LWFArad_data_example/radiationOpenPMD/e_radiation_10700_0_0_0.h5\"\n",
    "log_plots = visualizations.log_one_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33dee9-0a47-417c-bc43-c852c6376e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k, l = 0, len(paths_to_radiation);\n",
    "for ind,elem in enumerate(paths_to_radiation[k:l]):\n",
    "    #print(paths_to_radiation[ind].split('/')[-1].split('.')[0].split('_')[2])\n",
    "    rad = get_radiation_data(ind+k,paths_to_radiation,1)\n",
    "    rad = rad.detach().cpu().numpy()\n",
    "    #plt.plot(np.arange(rad.shape[-1]), rad[0,:], label=paths_to_radiation[ind+k].split('/')[-1].split('.')[0].split('_')[2])\n",
    "    plt.plot(np.arange(3953,3961), rad[0,3953:3961], label=paths_to_radiation[ind+k].split('/')[-1].split('.')[0].split('_')[2])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a807907a-d1cd-4544-a3ae-0bd8231cd7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in all_timesteps:\n",
    "    x = np.loadtxt(path)\n",
    "    figsize1 = 50\n",
    "    figsize2 = 5\n",
    "    labels_x = ['x', 'y', 'z', 'x', 'y', 'z']\n",
    "    labels_y = ['xp', 'yp', 'zp', 'xpp', 'ypp', 'zpp']\n",
    "    comp_xs = [0,1,2,0,1,2]\n",
    "    fig, axs = plt.subplots(1, 6, figsize=(figsize1,figsize2))\n",
    "    for i in range(6):\n",
    "        plot_2D(x, comp_x=comp_xs[i], comp_y=i+3, axs=axs[i], label_x=labels_x[i], label_y=labels_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e142c92-f0bc-47ad-98a1-4a8bb9449b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "models[0].device = 'cuda'\n",
    "models[0].to('cuda')\n",
    "#s = time.time()\n",
    "models[0].train_(datasets[0],\n",
    "               datasets[0],\n",
    "               optimizers[0],\n",
    "               epochs=1001,\n",
    "               batch_size=1,\n",
    "               test_epoch=100,\n",
    "               test_pointcloud=None, test_radiation=None, log_plots=None,\n",
    "               path_to_models='/bigdata/hplsim/aipp/Anna/all_timesteps_models/RESModels_'+supercell)\n",
    "#e = time.time()\n",
    "#print('time on cuda, MAF training: ', e-s, 's')\n",
    "#break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aebb8dc-d6ab-4f8d-a2e4-31319c80f442",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_size = 0\n",
    "for param in models[0].model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in models[0].model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d541b-559c-4b7c-8a4b-fd5d15c49faa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_x = ['x', 'y', 'z', 'x', 'y', 'z']\n",
    "labels_y = ['xp', 'yp', 'zp', 'xpp', 'ypp', 'zpp']\n",
    "\n",
    "for ind in range(len(all_timesteps)):\n",
    "    print(all_timesteps[ind].split('/')[-1].split('.')[0])\n",
    "    #print(paths_to_radiation[ind],'\\n')\n",
    "    x_ps = np.loadtxt(all_timesteps[ind])\n",
    "    rad = get_radiation_data(ind,paths_to_radiation,x_ps.shape[0])\n",
    "    vmin_rad, vmax_rad = torch.full((x_ps.shape[0],65536), datasets[0].vmin_rad_), torch.full((x_ps.shape[0], 65536), datasets[0].vmax_rad_)\n",
    "    rad = data_preprocessing.normalize_point(rad, vmin_rad, vmax_rad, datasets[0].a, datasets[0].b)\n",
    "    \n",
    "    x_ps_rec = models[0].sample_pointcloud(rad.to(models[0].device))\n",
    "    xyz = [int(elem) for elem in supercell.split('_')]\n",
    "\n",
    "    x_ps_rec = x_ps_rec[(x_ps_rec[:,0] < (xyz[0]+1)*8) & (x_ps_rec[:,0] > xyz[0]*8)\n",
    "                     & (x_ps_rec[:,1] < (xyz[1]+1)*8) & (x_ps_rec[:,1] > xyz[1]*8)\n",
    "                     & (x_ps_rec[:,2] < (xyz[2]+1)*4) & (x_ps_rec[:,2] > xyz[2]*4)]\n",
    "#                      & (x_ps_rec[:,3] > -10) & (x_ps_rec[:,3] < 10)\n",
    "#                        & (x_ps_rec[:,4] > -10) & (x_ps_rec[:,4] < 10)\n",
    "#                        & (x_ps_rec[:,5] > -10) & (x_ps_rec[:,5] < 10)\n",
    "#                        & (x_ps_rec[:,6] > -10) & (x_ps_rec[:,6] < 10)\n",
    "#                        & (x_ps_rec[:,7] > -10) & (x_ps_rec[:,7] < 10)\n",
    "#                        & (x_ps_rec[:,8] > -10) & (x_ps_rec[:,8] < 10)]\n",
    "    #x_ps_rec = reject_outliers(x_ps_rec.detach().cpu().numpy())\n",
    "    \n",
    "    figsize1 = 50\n",
    "    figsize2 = 5\n",
    "    fig, axs = plt.subplots(1, 6, figsize=(figsize1,figsize2))\n",
    "\n",
    "    for i in range(6):\n",
    "        plot_2D_GTandRec(x_ps, x_ps_rec,\n",
    "                         comp_x=comp_xs[i], comp_y=i+3, axs=axs[i],\n",
    "                         label_x=labels_x[i], label_y=labels_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a76fe9e-eee8-4db5-aa03-419e61c99a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#supercell = [int(k) for k in test_pointcloud.split('/')[-1].split('.')[0].split('_')[1:]]\n",
    "iteration = '10700'\n",
    "pointcloud_tensor = all_cells\n",
    "\n",
    "num_particles = 33284\n",
    "idx = np.random.randint(pointcloud_tensor.shape[0], size=num_particles)\n",
    "pointcloud_tensor = pointcloud_tensor[idx, :]\n",
    "radiation_tensor = torch.Tensor([0.5,0.5]).float().repeat(pointcloud_tensor.shape[0], 1)\n",
    "\n",
    "labels_x = ['x', 'y', 'z', 'x', 'y', 'z']\n",
    "labels_y = ['xp', 'yp', 'zp', 'xpp', 'ypp', 'zpp']\n",
    "\n",
    "pred_pointclouds = []\n",
    "for ind in range(len(supercells)):\n",
    "    radiation_tensor = torch.Tensor([0.5,0.5]).float().repeat(file_sizes[ind], 1)\n",
    "    pred_pointclouds.append((models[ind].sample_pointcloud(radiation_tensor.to(models[ind].device), radiation_tensor.shape[0])).detach().cpu().numpy())\n",
    "\n",
    "pred_pointcloud = np.concatenate([arr for arr in pred_pointclouds], axis=0)\n",
    "print(pred_pointcloud.shape)\n",
    "#pred_pointcloud = pred_pointcloud_full.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86933a08-7af1-4138-9639-e146e7e21adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize1 = 30\n",
    "figsize2 = 5\n",
    "fig, axs = plt.subplots(1, 6, figsize=(figsize1,figsize2))\n",
    "\n",
    "for i in range(6):\n",
    "    plot_2D_GTandRec(pointcloud_tensor, pred_pointcloud,\n",
    "                     comp_x=i, comp_y=i+3, axs=axs[i],\n",
    "                     label_x=labels_x[i], label_y=labels_y[i])\n",
    "    \n",
    "figsize1 = 30\n",
    "figsize2 = 5\n",
    "fig, axs = plt.subplots(1, 6, figsize=(figsize1,figsize2))\n",
    "for i in range(6):\n",
    "    plot_2D(pointcloud_tensor, comp_x=i, comp_y=i+3, axs=axs[i], label_x=labels_x[i], label_y=labels_y[i])\n",
    "\n",
    "figsize1 = 30\n",
    "figsize2 = 5\n",
    "fig, axs = plt.subplots(1, 6, figsize=(figsize1,figsize2))\n",
    "for i in range(6):\n",
    "    plot_2D(pred_pointcloud, comp_x=i, comp_y=i+3, axs=axs[i], label_x=labels_x[i], label_y=labels_y[i])\n",
    "    \n",
    "figsize1 = 30\n",
    "figsize2 = 10\n",
    "#labels = label_x+labels_y\n",
    "fig, axs = plt.subplots(3, 3, figsize=(figsize1,figsize2))\n",
    "for i in range(3):\n",
    "    plot_hist(pointcloud_tensor, pred_pointcloud, comp_x=i, axs=axs[0,i], label_x=labels_x[i])\n",
    "for i in range(3):\n",
    "    plot_hist(pointcloud_tensor, pred_pointcloud, comp_x=i+3, axs=axs[1,i], label_x=labels_y[i])\n",
    "    \n",
    "for i in range(3):\n",
    "    plot_hist(pointcloud_tensor, pred_pointcloud, comp_x=i+6, axs=axs[2,i], label_x=labels_y[i+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21887012-4d0c-44e0-982c-813d7c0dfe9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_per_slice(pc, slice_along, num_slices, comp_of_interest, axs, label='Number of particles'):\n",
    "    if comp_of_interest is not None:\n",
    "        comp_of_interest = comp_of_interest - 1\n",
    "\n",
    "    slices = [np.min(pc[:, slice_along]) + (np.max(pc[:, slice_along]) - np.min(pc[:, slice_along])) * i/num_slices for i in range(num_slices)]\n",
    "    pc_ = np.concatenate((pc, np.zeros((pc.shape[0], 1))), axis=1)\n",
    "\n",
    "    for ind in range(len(slices)-1):\n",
    "        pc_[:, -1][(pc_[:, slice_along]>=slices[ind]) & (pc_[:, slice_along]<=slices[ind+1])] = ind\n",
    "    pc_[:, -1][(pc_[:, slice_along]>=slices[-1])] = len(slices) - 1\n",
    "\n",
    "    if comp_of_interest is not None:\n",
    "        mean_energy = [np.mean(pc_[:, comp_of_interest][pc_[:,-1]==ind]) if (pc_[:, comp_of_interest][pc_[:,-1]==ind]).shape[0] > 1 else None for ind in range(len(slices))]\n",
    "        #std_energy = [np.std(pc_[:, comp_of_interest][pc_[:,-1]==ind]) if pc_[:, comp_of_interest][pc_[:,-1]==ind].shape[0] > 1 else None for ind in range(len(slices)) ]\n",
    "        axs.plot([slice_ for slice_ in slices], mean_energy)\n",
    "        axs.tick_params(axis='y', which='major', rotation=45)\n",
    "        axs.grid(True)\n",
    "        axs.set_xlabel('Z')\n",
    "        axs.set_ylabel(label)\n",
    "        #axs.legend(prop={'size': 20})\n",
    "\n",
    "    if comp_of_interest == None:\n",
    "        num_particles = [pc_[pc_[:,-1]==ind].shape[0] for ind in range(len(slices))]\n",
    "        axs.plot([slice_ for slice_ in slices], num_particles)\n",
    "        axs.tick_params(axis='y', which='major', rotation=45)\n",
    "        axs.grid(True)\n",
    "        axs.set_xlabel('Z')\n",
    "        axs.set_ylabel(label)\n",
    "        #axs.legend(prop={'size': 20})\n",
    "\n",
    "def plot_per_slice_GTandRec(pc, pc_pred, slice_along, num_slices, comp_of_interest, axs, label='Number of particles'):\n",
    "    if pc_pred is not None:\n",
    "        slices_pred = [np.min(pc_pred[:, slice_along]) + (np.max(pc_pred[:, slice_along]) - np.min(pc_pred[:, slice_along])) * i/num_slices for i in range(num_slices)]\n",
    "        pc_pred_ = np.concatenate((pc_pred, np.zeros((pc_pred.shape[0], 1))), axis=1)\n",
    "\n",
    "        for ind in range(len(slices_pred)-1):\n",
    "            pc_pred_[:, -1][(pc_pred_[:, -3]>=slices_pred[ind]) & (pc_pred_[:, -3]<=slices_pred[ind+1])] = ind\n",
    "        pc_pred_[:, -1][(pc_pred_[:, -3]>=slices_pred[-1])] = len(slices_pred) - 1\n",
    "    \n",
    "    if comp_of_interest is not None:\n",
    "        comp_of_interest = comp_of_interest - 1\n",
    "\n",
    "    slices = [np.min(pc[:, slice_along]) + (np.max(pc[:, slice_along]) - np.min(pc[:, slice_along])) * i/num_slices for i in range(num_slices)]\n",
    "    pc_ = np.concatenate((pc, np.zeros((pc.shape[0], 1))), axis=1)\n",
    "\n",
    "    for ind in range(len(slices)-1):\n",
    "        pc_[:, -1][(pc_[:, slice_along]>=slices[ind]) & (pc_[:, slice_along]<=slices[ind+1])] = ind\n",
    "    pc_[:, -1][(pc_[:, slice_along]>=slices[-1])] = len(slices) - 1\n",
    "\n",
    "    if comp_of_interest is not None:\n",
    "        mean_energy = [np.mean(pc_[:, comp_of_interest][pc_[:,-1]==ind]) if (pc_[:, comp_of_interest][pc_[:,-1]==ind]).shape[0] > 1 else None for ind in range(len(slices))]\n",
    "        std_energy = [np.std(pc_[:, comp_of_interest][pc_[:,-1]==ind]) if pc_[:, comp_of_interest][pc_[:,-1]==ind].shape[0] > 1 else None for ind in range(len(slices)) ]\n",
    "\n",
    "        #axs.plot([slice_ for slice_ in slices], mean_energy, label=\"Groundtruth\")\n",
    "        if pc_pred is not None:\n",
    "            print('plot pred', slices_pred)\n",
    "            mean_energy_pred = [np.mean(pc_pred_[:, comp_of_interest+1][pc_pred_[:,-1]==ind]) if (pc_pred_[:, comp_of_interest+1][pc_pred_[:,-1]==ind]).shape[0] > 1 else None for ind in range(len(slices_pred))]\n",
    "            std_energy_pred = [np.std(pc_pred_[:, comp_of_interest+1][pc_pred_[:,-1]==ind]) if pc_pred_[:, comp_of_interest+1][pc_pred_[:,-1]==ind].shape[0] > 1 else None for ind in range(len(slices_pred)) ]\n",
    "            axs.plot([slice_ for slice_ in slices_pred], mean_energy_pred, label=\"Reconstruction\")\n",
    "            \n",
    "        axs.tick_params(axis='y', which='major', rotation=45)\n",
    "        axs.grid(True)\n",
    "        axs.set_xlabel('Z')\n",
    "        axs.set_ylabel(label)\n",
    "        axs.legend(prop={'size': 20})\n",
    "\n",
    "\n",
    "    if comp_of_interest == None:\n",
    "        num_particles = [pc_[pc_[:,-1]==ind].shape[0] for ind in range(len(slices))]\n",
    "        axs.plot([slice_ for slice_ in slices], num_particles)\n",
    "        if pc_pred is not None:\n",
    "            num_particles_pred = [pc_pred_[pc_pred_[:,-1]==ind].shape[0] for ind in range(len(slices_pred))]\n",
    "            axs.plot([slice_ for slice_ in slices_pred], num_particles_pred)\n",
    "        axs.tick_params(axis='y', which='major', rotation=45)\n",
    "        axs.grid(True)\n",
    "        axs.set_xlabel('Z')\n",
    "        axs.set_ylabel(label)\n",
    "        #axs.legend(prop={'size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5176a9-cca9-4d75-9ea5-90d962a5fcbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slice_along = 2 #z: 2\n",
    "num_slices = 100\n",
    "comp_of_interest = -3\n",
    "figsize1 = 35\n",
    "figsize2 = 5\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(figsize1,figsize2))\n",
    "plot_per_slice_GTandRec(pointcloud_tensor, pred_pointcloud,\n",
    "                        slice_along, num_slices, comp_of_interest,\n",
    "                        axs[0], label='Number of particles')\n",
    "\n",
    "plot_per_slice(pred_pointcloud, slice_along, num_slices, comp_of_interest, axs[1], label='Number of particles')\n",
    "\n",
    "#for i in range(1,4,1):\n",
    "#    visualizations.plot_per_slice_GTandRec(pointcloud_tensor, pred_pointcloud,\n",
    "#                        slice_along, num_slices, comp_of_interest=-1*i,\n",
    "#                        axs=axs[i], label='Mean ' + labels_y[-1*i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a75c5-e0df-4aae-af2e-36c82ce76a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
